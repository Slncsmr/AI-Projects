{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad154987",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gradio openai-whisper requests\n",
    "pip install -q google-generativeai gradio Pillow\n",
    "\n",
    "import whisper\n",
    "import requests\n",
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "# ğŸ”‘ Gemini API Key\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Gemini API URL (for gemini-2.0-flash)\n",
    "GEMINI_URL = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}\"\n",
    "\n",
    "# Load Whisper Model\n",
    "whisper_model = whisper.load_model(\"base\")\n",
    "\n",
    "# ğŸ” Function to transcribe audio\n",
    "def transcribe_audio(audio_path):\n",
    "    try:\n",
    "        result = whisper_model.transcribe(audio_path)\n",
    "        return result[\"text\"]\n",
    "    except Exception as e:\n",
    "        return f\"âŒ Whisper Error: {str(e)}\"\n",
    "\n",
    "# ğŸ§  Ask Gemini a question\n",
    "def ask_gemini(question, context):\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        \"contents\": [\n",
    "            {\"role\": \"user\", \"parts\": [{\"text\": f\"Context:\\n{context}\\n\\nQuestion: {question}\"}]}\n",
    "        ]\n",
    "    }\n",
    "    response = requests.post(GEMINI_URL, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            return response.json()[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "        except:\n",
    "            return \"âš ï¸ Error parsing Gemini response\"\n",
    "    else:\n",
    "        return f\"âŒ API Error: {response.status_code} - {response.text}\"\n",
    "\n",
    "# ğŸ¯ Main Function\n",
    "def audio_chat(audio_path, question):\n",
    "    if not audio_path:\n",
    "        return \"âŒ Please upload an audio file.\"\n",
    "\n",
    "    # Step 1: Transcribe the audio\n",
    "    transcript = transcribe_audio(audio_path)\n",
    "\n",
    "    if \"âŒ\" in transcript:\n",
    "        return transcript\n",
    "\n",
    "    # Step 2: Ask Gemini with the transcript as context\n",
    "    answer = ask_gemini(question, transcript)\n",
    "\n",
    "    return f\"ğŸ“œ Transcription:\\n{transcript}\\n\\nğŸ’¬ Answer:\\n{answer}\"\n",
    "\n",
    "# ğŸ›ï¸ Gradio UI\n",
    "gr.Interface(\n",
    "    fn=audio_chat,\n",
    "    inputs=[\n",
    "        gr.Audio(label=\"Upload Audio\", type=\"filepath\"),\n",
    "        gr.Textbox(label=\"Ask a Question About the Audio\", placeholder=\"e.g., What is the main topic?\", lines=2)\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Answer\", lines=12),\n",
    "    title=\"ğŸ”Š Audio Q&A Chatbot\",\n",
    "    description=\"Upload an audio file and ask questions about its content using Whisper for transcription and Gemini for answers.\"\n",
    ").launch()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
